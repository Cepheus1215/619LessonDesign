{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算机视觉与图像处理实践课程设计自选项目：交通标志识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、小组成员\n",
    "组长：杨蕊欣  任务系数：1.10  \n",
    "负责查找资料与撰写文档  \n",
    "成员：龙子腾  任务系数：1.00  \n",
    "负责代码实现与调试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、项目环境  \n",
    "系统：Windows11 24H2  \n",
    "环境：Anaconda 2.6.0 + Jupyter NoteBook 7.0.8  \n",
    "框架：Pytorch 2.5.1 + CUDA 12.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、数据集信息  \n",
    "* 本项目使用的数据集为德国交通标志基准测试(German Traffic Sign Recognition Benchmark,GTSRB),它拥有43个类别及50000多张图片，适用于单图像、多分类的问题。\n",
    "* 数据集来源为Kaggle，下载地址：https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、项目实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.引入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from skimage import io, exposure, transform\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchviz import make_dot,make_dot_from_trace\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个模型，它接收的参数分别为`width`(宽度),`height`(高度),`depth`(深度),`classes`(类别数)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的总体结构为卷积层(`conv`)-全连接层(`fc`)-最大池化层(`pool`)，在每两层之间加入批量归一化层用于加速训练过程并提高模型稳定性。此外，应用Dropout以减少过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的前向传播路径为：  \n",
    "输入图像x首先通过第一个卷积层和批量归一化，然后应用ReLU激活函数和最大池化。  \n",
    "接着，图像通过第二和第三个卷积层（每个后面都有ReLU激活），然后再次池化。  \n",
    "图像继续通过第四和第五个卷积层（同样有ReLU激活），之后再次池化。  \n",
    "经过所有卷积和池化层后，使用`torch.flatten`将特征图展平为一维向量。  \n",
    "向量通过两个全连接层（每个后面都有ReLU激活和Dropout），最后通过输出层。  \n",
    "输出层的结果通过`F.log_softmax`进行对数软化最大处理，用于多分类任务。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignNet(nn.Module):\n",
    "    def __init__(self, width, height, depth, classes):\n",
    "        super(TrafficSignNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=depth, out_channels = 8, \n",
    "                               kernel_size = 5, padding = 2)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, \n",
    "                               kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, \n",
    "                               kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32,\n",
    "                               kernel_size=3, padding = 1)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32,\n",
    "                               kernel_size=3, padding = 1)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * (height // 8) * (width // 8), 128)\n",
    "        self.bn6 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.bn7 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.relu(self.bn6(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.bn7(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义数据集加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个数据集加载器，它接收的参数为`base_path`(图像文件的根目录路径)与`csv_path`(包含图像路径和标签信息的 CSV 文件路径)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)数据读取  \n",
    "打开csv文件，跳过文件的第一行，并对剩余行进行随机打乱，以增加数据集的多样性，随后遍历每一行，解析出标签和图像路径，并使用`os.path.join`将`base_path`和`image_path`合并成完整的图像文件路径。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)数据处理\n",
    "使用`io.imread`方法读取图像文件，随后对图像预处理，将其裁剪为32×32的大小并应用自适应直方图均衡化。将处理后的图像和标签分别添加到`self.data`和`self.labels`列表中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3)数据转换\n",
    "将`self.data`转换为NumPy数组，并将数据类型设置为float32，然后归一化到 [0, 1] 范围。  \n",
    "同理，将`self.labels`转换为 NumPy 数组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个方法，获取数据集的长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个方法，根据索引`idx`从数据集中获取单个图像和标签,将图像从 NumPy 数组转换为PyTorch张量，并调整通道顺序以符合PyTorch的输入格式。并将标签转换为 PyTorch 长整型张量。随后返回图像和标签的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficDataLoader(Dataset):\n",
    "    def __init__(self, base_path, csv_path):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        with open(csv_path, 'r') as f:\n",
    "            rows = f.read().strip().split(\"\\n\")[1:]#跳过文件的第一行\n",
    "            random.shuffle(rows)#对剩余行进行随机打乱\n",
    "            for row in rows:#遍历每一行，解析出标签和图像路径\n",
    "                label, image_path = row.strip().split(\",\")[-2:]\n",
    "                image_path = os.path.join(base_path, image_path)#使用 os.path.join 将 base_path 和 image_path 合并成完整的图像文件路径。\n",
    "                image = io.imread(image_path)#使用 io.imread读取图像文件\n",
    "                image = transform.resize(image, (32, 32))\n",
    "                image = exposure.equalize_adapthist(image, clip_limit=0.1)#应用自适应直方图均衡化\n",
    "                self.data.append(image)\n",
    "                self.labels.append(int(label))\n",
    "\n",
    "        self.data = np.array(self.data, dtype=\"float32\") / 255.0\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.data[idx].transpose((2,0,1)), dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义数据集的路径以及模型训练完成后的保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"dataset\": \"archive1/archive1/\",\n",
    "        \"model\":\"output/trafficsignnet.pth\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用`os.path.join`函数来构建训练集和测试集CSV文件的完整路径  \n",
    "* 使用上述数据加载器找到并处理数据\n",
    "* 将数据分成若干组，每组六十四个数据，并将数据的顺序打乱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(args[\"dataset\"], \"Train.csv\")\n",
    "test_path = os.path.join(args[\"dataset\"], \"Test.csv\")\n",
    "\n",
    "train_dataset = TrafficDataLoader(args[\"dataset\"], train_path)\n",
    "test_dataset = TrafficDataLoader(args[\"dataset\"], test_path)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle=False)\n",
    "\n",
    "model = TrafficSignNet(width=32, height=32, \n",
    "                       depth = 3, classes = len(np.unique(train_dataset.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将模型移动到GPU进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrafficSignNet(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (bn6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (bn7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=128, out_features=43, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5)损失函数与优化器  \n",
    "* 损失函数选择交叉熵损失函数（Cross Entropy Loss）,这是分类问题常用的损失函数\n",
    "* 优化器选用Adam优化器  \n",
    "* `model.parameters()`是一个生成器，它产生了模型中所有可训练的参数（通常是权重和偏置）。这些参数是优化器需要调整以减少损失函数的值的目标。  \n",
    "* 定义学习率lr=0.001，有助于模型更稳定地收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.模型训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1).定义训练函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先设置模型为训练模式，并初始化两个变量来跟踪在整个训练周期中正确预测的样本数和累积损失。使用`enumerate`来迭代`train_loader`，输出批次的索引和包含数据及其对应标签的元组。随后数据和标签都被移至GPU上。 \n",
    "\n",
    "执行训练循环\n",
    "* optimizer.zero_grad() 清空之前的梯度。\n",
    "* model(data) 执行前向传播，生成预测输出。\n",
    "* criterion(output, target) 计算损失。\n",
    "* loss.backward() 执行反向传播，计算梯度。\n",
    "* optimizer.step() 更新模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新累积损失，并通过比较预测和真实标签来计算正确预测的样本数，每处理 100 个批次，打印一次当前的训练进度和损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct_train += pred.eq(target).sum().item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}] Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)定义测试函数  \n",
    "先把模型设置为评估模式，并初始化两个变量:`test_loss`用于累加测试损失，`correct`用于计数正确预测的数量。   \n",
    "使用`torch.no_grad()`上下文管理器可以禁用梯度计算，这可以减少内存消耗并加速计算。  \n",
    "遍历测试数据加载器，每次迭代都会返回一个数据批次和对应的标签,并将数据和目标移动到GPU上。  \n",
    "通过模型进行前向传播，得到预测输出。  \n",
    "使用损失函数计算预测输出和目标之间的损失，并将损失值累加到test_loss中。注意，这里使用了.item()方法来获取损失值的标量表示。\n",
    "使用`argmax`方法获取预测类别的索引（即输出最大值所在的维度）。然后，使用`eq`方法比较预测和目标是否相等，得到一个布尔张量。最后，使用`sum`方法计算正确预测的数量，并使用`.item()`方法获取标量表示。  \n",
    "最后，将累加的测试损失除以测试数据集的总大小，得到平均测试损失，并打印测试集的平均损失和准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim = 1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)}({100. * correct / len(test_loader.dataset):.2f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/39209] Loss: 0.003247\n",
      "Train Epoch: 0 [6400/39209] Loss: 0.096513\n",
      "Train Epoch: 0 [12800/39209] Loss: 0.000312\n",
      "Train Epoch: 0 [19200/39209] Loss: 0.027977\n",
      "Train Epoch: 0 [25600/39209] Loss: 0.042443\n",
      "Train Epoch: 0 [32000/39209] Loss: 0.001552\n",
      "Train Epoch: 0 [38400/39209] Loss: 0.037046\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 10376/12630(82.15%)\n",
      "\n",
      "Train Epoch: 1 [0/39209] Loss: 0.054251\n",
      "Train Epoch: 1 [6400/39209] Loss: 0.026209\n",
      "Train Epoch: 1 [12800/39209] Loss: 0.022493\n",
      "Train Epoch: 1 [19200/39209] Loss: 0.010693\n",
      "Train Epoch: 1 [25600/39209] Loss: 0.034440\n",
      "Train Epoch: 1 [32000/39209] Loss: 0.001128\n",
      "Train Epoch: 1 [38400/39209] Loss: 0.012383\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 11506/12630(91.10%)\n",
      "\n",
      "Train Epoch: 2 [0/39209] Loss: 0.003479\n",
      "Train Epoch: 2 [6400/39209] Loss: 0.000923\n",
      "Train Epoch: 2 [12800/39209] Loss: 0.001812\n",
      "Train Epoch: 2 [19200/39209] Loss: 0.016910\n",
      "Train Epoch: 2 [25600/39209] Loss: 0.002193\n",
      "Train Epoch: 2 [32000/39209] Loss: 0.002609\n",
      "Train Epoch: 2 [38400/39209] Loss: 0.005652\n",
      "\n",
      "Test set: Average loss: 0.0080, Accuracy: 11286/12630(89.36%)\n",
      "\n",
      "Train Epoch: 3 [0/39209] Loss: 0.006529\n",
      "Train Epoch: 3 [6400/39209] Loss: 0.000480\n",
      "Train Epoch: 3 [12800/39209] Loss: 0.017126\n",
      "Train Epoch: 3 [19200/39209] Loss: 0.021006\n",
      "Train Epoch: 3 [25600/39209] Loss: 0.027458\n",
      "Train Epoch: 3 [32000/39209] Loss: 0.000354\n",
      "Train Epoch: 3 [38400/39209] Loss: 0.007980\n",
      "\n",
      "Test set: Average loss: 0.0049, Accuracy: 11799/12630(93.42%)\n",
      "\n",
      "Train Epoch: 4 [0/39209] Loss: 0.075568\n",
      "Train Epoch: 4 [6400/39209] Loss: 0.000419\n",
      "Train Epoch: 4 [12800/39209] Loss: 0.000478\n",
      "Train Epoch: 4 [19200/39209] Loss: 0.001941\n",
      "Train Epoch: 4 [25600/39209] Loss: 0.016430\n",
      "Train Epoch: 4 [32000/39209] Loss: 0.000405\n",
      "Train Epoch: 4 [38400/39209] Loss: 0.086283\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 12019/12630(95.16%)\n",
      "\n",
      "Train Epoch: 5 [0/39209] Loss: 0.001277\n",
      "Train Epoch: 5 [6400/39209] Loss: 0.004119\n",
      "Train Epoch: 5 [12800/39209] Loss: 0.059309\n",
      "Train Epoch: 5 [19200/39209] Loss: 0.000221\n",
      "Train Epoch: 5 [25600/39209] Loss: 0.001031\n",
      "Train Epoch: 5 [32000/39209] Loss: 0.004656\n",
      "Train Epoch: 5 [38400/39209] Loss: 0.000312\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 12150/12630(96.20%)\n",
      "\n",
      "Train Epoch: 6 [0/39209] Loss: 0.009918\n",
      "Train Epoch: 6 [6400/39209] Loss: 0.001930\n",
      "Train Epoch: 6 [12800/39209] Loss: 0.021717\n",
      "Train Epoch: 6 [19200/39209] Loss: 0.023051\n",
      "Train Epoch: 6 [25600/39209] Loss: 0.010821\n",
      "Train Epoch: 6 [32000/39209] Loss: 0.022030\n",
      "Train Epoch: 6 [38400/39209] Loss: 0.005045\n",
      "\n",
      "Test set: Average loss: 0.0061, Accuracy: 11525/12630(91.25%)\n",
      "\n",
      "Train Epoch: 7 [0/39209] Loss: 0.000139\n",
      "Train Epoch: 7 [6400/39209] Loss: 0.015058\n",
      "Train Epoch: 7 [12800/39209] Loss: 0.000319\n",
      "Train Epoch: 7 [19200/39209] Loss: 0.023704\n",
      "Train Epoch: 7 [25600/39209] Loss: 0.203524\n",
      "Train Epoch: 7 [32000/39209] Loss: 0.013903\n",
      "Train Epoch: 7 [38400/39209] Loss: 0.001394\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 10368/12630(82.09%)\n",
      "\n",
      "Train Epoch: 8 [0/39209] Loss: 0.001372\n",
      "Train Epoch: 8 [6400/39209] Loss: 0.010432\n",
      "Train Epoch: 8 [12800/39209] Loss: 0.000099\n",
      "Train Epoch: 8 [19200/39209] Loss: 0.008414\n",
      "Train Epoch: 8 [25600/39209] Loss: 0.040870\n",
      "Train Epoch: 8 [32000/39209] Loss: 0.000154\n",
      "Train Epoch: 8 [38400/39209] Loss: 0.005431\n",
      "\n",
      "Test set: Average loss: 0.0479, Accuracy: 7570/12630(59.94%)\n",
      "\n",
      "Train Epoch: 9 [0/39209] Loss: 0.012612\n",
      "Train Epoch: 9 [6400/39209] Loss: 0.016368\n",
      "Train Epoch: 9 [12800/39209] Loss: 0.014070\n",
      "Train Epoch: 9 [19200/39209] Loss: 0.009168\n",
      "Train Epoch: 9 [25600/39209] Loss: 0.001849\n",
      "Train Epoch: 9 [32000/39209] Loss: 0.003000\n",
      "Train Epoch: 9 [38400/39209] Loss: 0.006422\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 12003/12630(95.04%)\n",
      "\n",
      "Train Epoch: 10 [0/39209] Loss: 0.042430\n",
      "Train Epoch: 10 [6400/39209] Loss: 0.044391\n",
      "Train Epoch: 10 [12800/39209] Loss: 0.001192\n",
      "Train Epoch: 10 [19200/39209] Loss: 0.006318\n",
      "Train Epoch: 10 [25600/39209] Loss: 0.002646\n",
      "Train Epoch: 10 [32000/39209] Loss: 0.003694\n",
      "Train Epoch: 10 [38400/39209] Loss: 0.017756\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 12223/12630(96.78%)\n",
      "\n",
      "Train Epoch: 11 [0/39209] Loss: 0.000109\n",
      "Train Epoch: 11 [6400/39209] Loss: 0.090579\n",
      "Train Epoch: 11 [12800/39209] Loss: 0.010634\n",
      "Train Epoch: 11 [19200/39209] Loss: 0.006308\n",
      "Train Epoch: 11 [25600/39209] Loss: 0.000554\n",
      "Train Epoch: 11 [32000/39209] Loss: 0.040962\n",
      "Train Epoch: 11 [38400/39209] Loss: 0.000628\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 12047/12630(95.38%)\n",
      "\n",
      "Train Epoch: 12 [0/39209] Loss: 0.003355\n",
      "Train Epoch: 12 [6400/39209] Loss: 0.001930\n",
      "Train Epoch: 12 [12800/39209] Loss: 0.109419\n",
      "Train Epoch: 12 [19200/39209] Loss: 0.004890\n",
      "Train Epoch: 12 [25600/39209] Loss: 0.008446\n",
      "Train Epoch: 12 [32000/39209] Loss: 0.030201\n",
      "Train Epoch: 12 [38400/39209] Loss: 0.001246\n",
      "\n",
      "Test set: Average loss: 0.0028, Accuracy: 12206/12630(96.64%)\n",
      "\n",
      "Train Epoch: 13 [0/39209] Loss: 0.012724\n",
      "Train Epoch: 13 [6400/39209] Loss: 0.007415\n",
      "Train Epoch: 13 [12800/39209] Loss: 0.011974\n",
      "Train Epoch: 13 [19200/39209] Loss: 0.005990\n",
      "Train Epoch: 13 [25600/39209] Loss: 0.055241\n",
      "Train Epoch: 13 [32000/39209] Loss: 0.006510\n",
      "Train Epoch: 13 [38400/39209] Loss: 0.078888\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 12087/12630(95.70%)\n",
      "\n",
      "Train Epoch: 14 [0/39209] Loss: 0.012937\n",
      "Train Epoch: 14 [6400/39209] Loss: 0.062529\n",
      "Train Epoch: 14 [12800/39209] Loss: 0.001097\n",
      "Train Epoch: 14 [19200/39209] Loss: 0.000240\n",
      "Train Epoch: 14 [25600/39209] Loss: 0.000557\n",
      "Train Epoch: 14 [32000/39209] Loss: 0.014563\n",
      "Train Epoch: 14 [38400/39209] Loss: 0.009215\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 10848/12630(85.89%)\n",
      "\n",
      "Train Epoch: 15 [0/39209] Loss: 0.000141\n",
      "Train Epoch: 15 [6400/39209] Loss: 0.039720\n",
      "Train Epoch: 15 [12800/39209] Loss: 0.000865\n",
      "Train Epoch: 15 [19200/39209] Loss: 0.000123\n",
      "Train Epoch: 15 [25600/39209] Loss: 0.018444\n",
      "Train Epoch: 15 [32000/39209] Loss: 0.000252\n",
      "Train Epoch: 15 [38400/39209] Loss: 0.035173\n",
      "\n",
      "Test set: Average loss: 0.0042, Accuracy: 11948/12630(94.60%)\n",
      "\n",
      "Train Epoch: 16 [0/39209] Loss: 0.000865\n",
      "Train Epoch: 16 [6400/39209] Loss: 0.002022\n",
      "Train Epoch: 16 [12800/39209] Loss: 0.002002\n",
      "Train Epoch: 16 [19200/39209] Loss: 0.038235\n",
      "Train Epoch: 16 [25600/39209] Loss: 0.017317\n",
      "Train Epoch: 16 [32000/39209] Loss: 0.001169\n",
      "Train Epoch: 16 [38400/39209] Loss: 0.016040\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 11941/12630(94.54%)\n",
      "\n",
      "Train Epoch: 17 [0/39209] Loss: 0.036204\n",
      "Train Epoch: 17 [6400/39209] Loss: 0.003818\n",
      "Train Epoch: 17 [12800/39209] Loss: 0.062390\n",
      "Train Epoch: 17 [19200/39209] Loss: 0.000990\n",
      "Train Epoch: 17 [25600/39209] Loss: 0.039893\n",
      "Train Epoch: 17 [32000/39209] Loss: 0.011315\n",
      "Train Epoch: 17 [38400/39209] Loss: 0.088663\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 12153/12630(96.22%)\n",
      "\n",
      "Train Epoch: 18 [0/39209] Loss: 0.033206\n",
      "Train Epoch: 18 [6400/39209] Loss: 0.003991\n",
      "Train Epoch: 18 [12800/39209] Loss: 0.007320\n",
      "Train Epoch: 18 [19200/39209] Loss: 0.002455\n",
      "Train Epoch: 18 [25600/39209] Loss: 0.002709\n",
      "Train Epoch: 18 [32000/39209] Loss: 0.010033\n",
      "Train Epoch: 18 [38400/39209] Loss: 0.004217\n",
      "\n",
      "Test set: Average loss: 0.0080, Accuracy: 11255/12630(89.11%)\n",
      "\n",
      "Train Epoch: 19 [0/39209] Loss: 0.055234\n",
      "Train Epoch: 19 [6400/39209] Loss: 0.006619\n",
      "Train Epoch: 19 [12800/39209] Loss: 0.048121\n",
      "Train Epoch: 19 [19200/39209] Loss: 0.000972\n",
      "Train Epoch: 19 [25600/39209] Loss: 0.022130\n",
      "Train Epoch: 19 [32000/39209] Loss: 0.024760\n",
      "Train Epoch: 19 [38400/39209] Loss: 0.004008\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 12002/12630(95.03%)\n",
      "\n",
      "Train Epoch: 20 [0/39209] Loss: 0.001523\n",
      "Train Epoch: 20 [6400/39209] Loss: 0.001308\n",
      "Train Epoch: 20 [12800/39209] Loss: 0.029913\n",
      "Train Epoch: 20 [19200/39209] Loss: 0.004177\n",
      "Train Epoch: 20 [25600/39209] Loss: 0.027856\n",
      "Train Epoch: 20 [32000/39209] Loss: 0.002544\n",
      "Train Epoch: 20 [38400/39209] Loss: 0.000977\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 11913/12630(94.32%)\n",
      "\n",
      "Train Epoch: 21 [0/39209] Loss: 0.015668\n",
      "Train Epoch: 21 [6400/39209] Loss: 0.001676\n",
      "Train Epoch: 21 [12800/39209] Loss: 0.029016\n",
      "Train Epoch: 21 [19200/39209] Loss: 0.003381\n",
      "Train Epoch: 21 [25600/39209] Loss: 0.005635\n",
      "Train Epoch: 21 [32000/39209] Loss: 0.004091\n",
      "Train Epoch: 21 [38400/39209] Loss: 0.012083\n",
      "\n",
      "Test set: Average loss: 0.1259, Accuracy: 1531/12630(12.12%)\n",
      "\n",
      "Train Epoch: 22 [0/39209] Loss: 0.003443\n",
      "Train Epoch: 22 [6400/39209] Loss: 0.001921\n",
      "Train Epoch: 22 [12800/39209] Loss: 0.000529\n",
      "Train Epoch: 22 [19200/39209] Loss: 0.011192\n",
      "Train Epoch: 22 [25600/39209] Loss: 0.002678\n",
      "Train Epoch: 22 [32000/39209] Loss: 0.003198\n",
      "Train Epoch: 22 [38400/39209] Loss: 0.037516\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 12013/12630(95.11%)\n",
      "\n",
      "Train Epoch: 23 [0/39209] Loss: 0.016143\n",
      "Train Epoch: 23 [6400/39209] Loss: 0.007415\n",
      "Train Epoch: 23 [12800/39209] Loss: 0.028253\n",
      "Train Epoch: 23 [19200/39209] Loss: 0.001814\n",
      "Train Epoch: 23 [25600/39209] Loss: 0.015139\n",
      "Train Epoch: 23 [32000/39209] Loss: 0.042335\n",
      "Train Epoch: 23 [38400/39209] Loss: 0.015303\n",
      "\n",
      "Test set: Average loss: 0.0032, Accuracy: 12108/12630(95.87%)\n",
      "\n",
      "Train Epoch: 24 [0/39209] Loss: 0.002290\n",
      "Train Epoch: 24 [6400/39209] Loss: 0.021003\n",
      "Train Epoch: 24 [12800/39209] Loss: 0.005910\n",
      "Train Epoch: 24 [19200/39209] Loss: 0.003561\n",
      "Train Epoch: 24 [25600/39209] Loss: 0.025881\n",
      "Train Epoch: 24 [32000/39209] Loss: 0.013451\n",
      "Train Epoch: 24 [38400/39209] Loss: 0.001500\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 12074/12630(95.60%)\n",
      "\n",
      "Train Epoch: 25 [0/39209] Loss: 0.001749\n",
      "Train Epoch: 25 [6400/39209] Loss: 0.000794\n",
      "Train Epoch: 25 [12800/39209] Loss: 0.026146\n",
      "Train Epoch: 25 [19200/39209] Loss: 0.003596\n",
      "Train Epoch: 25 [25600/39209] Loss: 0.002837\n",
      "Train Epoch: 25 [32000/39209] Loss: 0.001251\n",
      "Train Epoch: 25 [38400/39209] Loss: 0.022166\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 11885/12630(94.10%)\n",
      "\n",
      "Train Epoch: 26 [0/39209] Loss: 0.002003\n",
      "Train Epoch: 26 [6400/39209] Loss: 0.009283\n",
      "Train Epoch: 26 [12800/39209] Loss: 0.015000\n",
      "Train Epoch: 26 [19200/39209] Loss: 0.002622\n",
      "Train Epoch: 26 [25600/39209] Loss: 0.019029\n",
      "Train Epoch: 26 [32000/39209] Loss: 0.008145\n",
      "Train Epoch: 26 [38400/39209] Loss: 0.001132\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 11917/12630(94.35%)\n",
      "\n",
      "Train Epoch: 27 [0/39209] Loss: 0.112083\n",
      "Train Epoch: 27 [6400/39209] Loss: 0.006298\n",
      "Train Epoch: 27 [12800/39209] Loss: 0.003140\n",
      "Train Epoch: 27 [19200/39209] Loss: 0.000630\n",
      "Train Epoch: 27 [25600/39209] Loss: 0.000556\n",
      "Train Epoch: 27 [32000/39209] Loss: 0.001290\n",
      "Train Epoch: 27 [38400/39209] Loss: 0.000265\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 12137/12630(96.10%)\n",
      "\n",
      "Train Epoch: 28 [0/39209] Loss: 0.000948\n",
      "Train Epoch: 28 [6400/39209] Loss: 0.026402\n",
      "Train Epoch: 28 [12800/39209] Loss: 0.005660\n",
      "Train Epoch: 28 [19200/39209] Loss: 0.000284\n",
      "Train Epoch: 28 [25600/39209] Loss: 0.002210\n",
      "Train Epoch: 28 [32000/39209] Loss: 0.016453\n",
      "Train Epoch: 28 [38400/39209] Loss: 0.002562\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 12155/12630(96.24%)\n",
      "\n",
      "Train Epoch: 29 [0/39209] Loss: 0.001443\n",
      "Train Epoch: 29 [6400/39209] Loss: 0.007340\n",
      "Train Epoch: 29 [12800/39209] Loss: 0.000139\n",
      "Train Epoch: 29 [19200/39209] Loss: 0.007325\n",
      "Train Epoch: 29 [25600/39209] Loss: 0.022493\n",
      "Train Epoch: 29 [32000/39209] Loss: 0.000521\n",
      "Train Epoch: 29 [38400/39209] Loss: 0.001694\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 12088/12630(95.71%)\n",
      "\n",
      "Train Epoch: 30 [0/39209] Loss: 0.017218\n",
      "Train Epoch: 30 [6400/39209] Loss: 0.000760\n",
      "Train Epoch: 30 [12800/39209] Loss: 0.023025\n",
      "Train Epoch: 30 [19200/39209] Loss: 0.006705\n",
      "Train Epoch: 30 [25600/39209] Loss: 0.000561\n",
      "Train Epoch: 30 [32000/39209] Loss: 0.000036\n",
      "Train Epoch: 30 [38400/39209] Loss: 0.030115\n",
      "\n",
      "Test set: Average loss: 0.0029, Accuracy: 12144/12630(96.15%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "for epoch in range(0, num_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "torch.save(model.state_dict(), args[\"model\"])\n",
    "torch.save(model,'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3)打印分类报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将模型设置为评估模式，并禁用梯度计算。  \n",
    "* 遍历测试数据加载器`test_loader`。按批次加载测试数据集。每个批次包含一对data和target。并将数据和目标移动到GPU上。  \n",
    "* 模型对输入数据进行前向传播，得到模型的输出`output`  。\n",
    "* 使用`argmax(dim=1)`方法沿着类别维度找到最大值的索引，即模型预测的类别。然后使用`.cpu()`将结果移动到CPU上。最后，使用`.numpy()`将结果转换为NumPy数组，以便与`sklearn`的`classification_report`函数兼容。  \n",
    "* 将当前批次的预测结果`preds`和真实标签`target`分别添加到`test_preds`和`test_targets`列表中,用于存储所有测试样本的预测结果和真实标签.  \n",
    "* 打印出模型的分类报告，以便根据报告在后续改进模型或训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        60\n",
      "           1       0.98      0.98      0.98       720\n",
      "           2       0.94      0.99      0.96       750\n",
      "           3       0.98      0.95      0.96       450\n",
      "           4       0.99      0.97      0.98       660\n",
      "           5       0.94      0.94      0.94       630\n",
      "           6       1.00      0.84      0.91       150\n",
      "           7       0.98      0.96      0.97       450\n",
      "           8       0.91      0.99      0.95       450\n",
      "           9       0.99      0.98      0.98       480\n",
      "          10       0.99      0.98      0.98       660\n",
      "          11       0.91      0.95      0.93       420\n",
      "          12       1.00      0.99      0.99       690\n",
      "          13       0.99      1.00      1.00       720\n",
      "          14       0.99      1.00      1.00       270\n",
      "          15       0.99      0.98      0.98       210\n",
      "          16       1.00      1.00      1.00       150\n",
      "          17       1.00      0.99      0.99       360\n",
      "          18       0.99      0.85      0.91       390\n",
      "          19       1.00      0.87      0.93        60\n",
      "          20       0.93      0.97      0.95        90\n",
      "          21       0.85      0.61      0.71        90\n",
      "          22       0.99      0.90      0.94       120\n",
      "          23       0.89      0.98      0.93       150\n",
      "          24       0.70      0.96      0.81        90\n",
      "          25       0.97      0.94      0.96       480\n",
      "          26       0.98      0.82      0.89       180\n",
      "          27       0.52      0.57      0.54        60\n",
      "          28       0.91      0.99      0.95       150\n",
      "          29       0.97      0.99      0.98        90\n",
      "          30       0.82      0.86      0.84       150\n",
      "          31       0.94      0.97      0.96       270\n",
      "          32       0.98      0.97      0.97        60\n",
      "          33       0.99      1.00      0.99       210\n",
      "          34       0.98      0.98      0.98       120\n",
      "          35       1.00      0.98      0.99       390\n",
      "          36       0.99      0.98      0.99       120\n",
      "          37       0.98      0.98      0.98        60\n",
      "          38       0.99      0.99      0.99       690\n",
      "          39       1.00      0.98      0.99        90\n",
      "          40       0.85      0.98      0.91        90\n",
      "          41       0.84      0.97      0.90        60\n",
      "          42       0.90      0.90      0.90        90\n",
      "\n",
      "    accuracy                           0.96     12630\n",
      "   macro avg       0.94      0.94      0.94     12630\n",
      "weighted avg       0.96      0.96      0.96     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "test_targets = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        preds = output.argmax(dim=1).cpu().numpy()\n",
    "        test_preds.extend(preds)\n",
    "        test_targets.extend(target.numpy())\n",
    "\n",
    "print(classification_report(test_targets, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.使用模型进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)定义**被预测图片**的路径与**预测结果**的输出路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_args = {\"model\":\"output/trafficsignnet.pth\",\n",
    "        \"images\":\"test1/test\",\n",
    "        \"pred\":\"output/preds/\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 引入训练好的模型，打开一个包含交通标志名称CSV文件，读取所有内容，去除首尾空白字符，然后按行分割成列表。\n",
    "* `split(\"\\n\")[1:]`跳过第一行，只保留了包含数据的行。\n",
    "* `[l.split(\",\")[1] for l in labelNames]`对每一行进行分割,以逗号为分隔符提取第二列的内容，因为第二列为各交通标志的名称。最后输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Speed limit (20km/h)', 'Speed limit (30km/h)', 'Speed limit (50km/h)', 'Speed limit (60km/h)', 'Speed limit (70km/h)', 'Speed limit (80km/h)', 'End of speed limit (80km/h)', 'Speed limit (100km/h)', 'Speed limit (120km/h)', 'No passing', 'No passing for vehicles over 3.5 metric tons', 'Right-of-way at the next intersection', 'Priority road', 'Yield', 'Stop', 'No vehicles', 'Vehicles over 3.5 metric tons prohibited', 'No entry', 'General caution', 'Dangerous curve to the left', 'Dangerous curve to the right', 'Double curve', 'Bumpy road', 'Slippery road', 'Road narrows on the right', 'Road work', 'Traffic signals', 'Pedestrians', 'Children crossing', 'Bicycles crossing', 'Beware of ice/snow', 'Wild animals crossing', 'End of all speed and passing limits', 'Turn right ahead', 'Turn left ahead', 'Ahead only', 'Go straight or right', 'Go straight or left', 'Keep right', 'Keep left', 'Roundabout mandatory', 'End of no passing', 'End of no passing by vehicles over 3.5 metric']\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)#忽略了一个FutureWarning，不影响最终的输出结果\n",
    "model = TrafficSignNet(width=32, height=32, \n",
    "                       depth = 3, classes = len(np.unique(train_dataset.labels)))\n",
    "model.load_state_dict(torch.load(pred_args[\"model\"]))\n",
    "\n",
    "labelNames = open(\"./archive1/archive1/signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
    "labelNames = [l.split(\",\")[1] for l in labelNames]\n",
    "print(labelNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)对给定图像进行推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用`imutils.paths`中的`list_images`方法列出指定目录下的所有图像文件路径,随后打乱图像路径列表的顺序。\n",
    "* 使用`io.imread`读取图像文件，并进行一系列处理。\n",
    "* 使用`OpenCV`再次读取图像,并使用`cv2.putText`方法在图像上添加文本标签，显示预测的类别。\n",
    "* 使用`os.path.sep.join`构建保存预测图像的路径，`cv2.imwrite`保存图像到指定路径(./output/preds/)，统一以png格式保存。\n",
    "* 处理完成后输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicts done！\n"
     ]
    }
   ],
   "source": [
    "imagePaths = list(paths.list_images(pred_args[\"images\"]))\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "for i, imagePath in enumerate(imagePaths):\n",
    "    image = io.imread(imagePath)\n",
    "    image = transform.resize(image, (32, 32))\n",
    "    image = exposure.equalize_adapthist(image, clip_limit=0.1)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    \n",
    "    j = np.argmax(preds.numpy(), axis=1)[0]\n",
    "    label = labelNames[j]\n",
    "\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    cv2.putText(image, label, (5, 15), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.45, (0, 0, 255), 1)\n",
    "    \n",
    "    p = os.path.sep.join([\"output/preds/\", \"{}.png\".format(i)])\n",
    "    cv2.imwrite(p, image)\n",
    "print(\" predicts done！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五、项目价值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于GTSRB数据集进行深度学习实现交通标志识别，对于提升道路交通安全性、推动智能交通系统发展具有深远意义。它能够高效准确地识别各类交通标志，为驾驶员提供及时准确的道路信息，有效减少因误解或忽视交通标志而导致的交通事故。同时，该技术也是自动驾驶技术的重要组成部分，为实现车辆自主导航、智能避障等功能提供了有力支持，有助于构建更加安全、高效的未来交通体系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 六、遇到问题及解决方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题1：模型准确率不高，训练时间长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 解决方法：对模型重新进行训练，增加训练轮次，或更换优化器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题2：引入的库较多，使用不熟练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 解决方法：在网上查询资料及文献，学习相应的使用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七、收获"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用PyTorch处理德国交通标志识别基准（GTSRB）数据集进行交通标志识别的过程中，使我们深刻体会到了深度学习在图像分类任务中的强大能力。通过数据预处理、模型构建、训练与调优等一系列步骤，我不仅掌握了PyTorch框架的基本操作和高级特性，还学会了如何有效地处理大规模图像数据集。此外，通过调整模型架构、优化器选择以及学习率调度策略，我深刻理解了这些超参数对模型性能的影响。更重要的是，通过解决过拟合、类别不平衡等挑战，我们学会了如何运用正则化方法、数据增强技术和损失函数调整等手段来提升模型的泛化能力。整个项目不仅锻炼了编程实践能力，还加深了对深度学习原理的理解，为我们在计算机视觉领域的进一步探索奠定了坚实的基础。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
